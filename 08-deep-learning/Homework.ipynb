{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a525d87d-b078-4dca-ae1d-6853bd393240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b3b940-49fd-4f70-a91f-9acd0b88a727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320000, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        \n",
    "        # Input: (3, 200, 200)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding=1  # keeps spatial size before pooling\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # After Conv + Pooling:\n",
    "        # 200x200 -> Conv(3x3 same padding) → 200x200\n",
    "        # 200x200 -> MaxPool2d(2x2) → 100x100\n",
    "        # So tensor shape becomes: (32, 100, 100)\n",
    "        self.flatten_dim = 32 * 100 * 100\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()  # output for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "model = MyCNN()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c3f93-500c-4cef-88bd-2bf0f04bf10f",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which loss function you will use?\n",
    "\n",
    "- nn.MSELoss()\n",
    "- nn.BCEWithLogitsLoss()\n",
    "- nn.CrossEntropyLoss()\n",
    "- nn.CosineEmbeddingLoss()\n",
    "(Multiple answered can be correct, so pick any)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c25567-ab4d-4e33-8da0-3cb33a19c1fb",
   "metadata": {},
   "source": [
    "Answer: nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616fb615-5439-4d24-ae6d-b6243109b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefdf0a-2ac6-4d91-ac2e-1bc8a7728321",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use torchsummary or count manually.\n",
    "\n",
    "- 896\n",
    "- 11214912\n",
    "- 15896912\n",
    "- 20073473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ad62a7-35c9-4b1c-a674-5ad07f1e2d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 200, 200]             896\n",
      "         MaxPool2d-2         [-1, 32, 100, 100]               0\n",
      "            Linear-3                   [-1, 64]      20,480,064\n",
      "            Linear-4                    [-1, 1]              65\n",
      "================================================================\n",
      "Total params: 20,481,025\n",
      "Trainable params: 20,481,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 12.21\n",
      "Params size (MB): 78.13\n",
      "Estimated Total Size (MB): 90.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 200, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9733169f-082b-4ef2-8cbe-1de96eafb079",
   "metadata": {},
   "source": [
    "Answer: 20,481,025 (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35268c03-8914-47bb-add8-f44d407d250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72042e5b-bb87-4cc6-9064-63824ce451bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 800\n",
      "Test samples: 201\n",
      "Classes: ['curly', 'straight']\n"
     ]
    }
   ],
   "source": [
    "# ---- Paths to your data ----\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "# ---- Create dataset objects ----\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=train_dir,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "validation_dataset = datasets.ImageFolder(\n",
    "    root=test_dir,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "# ---- Create DataLoaders ----\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=20,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=20,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Test samples:\", len(validation_dataset))\n",
    "print(\"Classes:\", train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5107796-af2b-466c-894a-fe722a01d89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=320000, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "068d62f4-d65a-4d3c-8075-ef34aca5b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7348, Acc: 0.6050, Val Loss: 0.6205, Val Acc: 0.7114\n",
      "Epoch 2/10, Loss: 0.5957, Acc: 0.6863, Val Loss: 0.5998, Val Acc: 0.7065\n",
      "Epoch 3/10, Loss: 0.5777, Acc: 0.6975, Val Loss: 0.5821, Val Acc: 0.7015\n",
      "Epoch 4/10, Loss: 0.5630, Acc: 0.7000, Val Loss: 0.6790, Val Acc: 0.7214\n",
      "Epoch 5/10, Loss: 0.5397, Acc: 0.7063, Val Loss: 0.5979, Val Acc: 0.7264\n",
      "Epoch 6/10, Loss: 0.5301, Acc: 0.7425, Val Loss: 0.5909, Val Acc: 0.7264\n",
      "Epoch 7/10, Loss: 0.5276, Acc: 0.7450, Val Loss: 0.6132, Val Acc: 0.7264\n",
      "Epoch 8/10, Loss: 0.4894, Acc: 0.7312, Val Loss: 0.6141, Val Acc: 0.7114\n",
      "Epoch 9/10, Loss: 0.5091, Acc: 0.7312, Val Loss: 0.5602, Val Acc: 0.7264\n",
      "Epoch 10/10, Loss: 0.4895, Acc: 0.7588, Val Loss: 0.5560, Val Acc: 0.7363\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca85018-8520-4fb2-b8db-cfa5f80f8a5c",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.05\n",
    "- 0.12\n",
    "- 0.40\n",
    "- 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b2fa9-0c98-4eb0-9b6d-2ae80355b916",
   "metadata": {},
   "source": [
    "Answer: d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd208a-8a2d-4309-b440-b8f8f970ac61",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.007\n",
    "- 0.078\n",
    "- 0.171\n",
    "- 1.710"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc8bb6-3838-400d-9e5d-f91eaf45538a",
   "metadata": {},
   "source": [
    "Answer: 0.149163640192761 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7633b60b-a4f1-4fdc-95a3-8450305510b8",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "Note: make sure you don't re-create the model. we want to continue training the model we already started training.\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.008\n",
    "- 0.08\n",
    "- 0.88\n",
    "- 8.88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa3674-fa8a-4f26-84c7-7f540072bdf2",
   "metadata": {},
   "source": [
    "Answer: (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5da71e-6ebd-4f4c-9bb2-93bae236c7fb",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "- 0.08\n",
    "- 0.28\n",
    "- 0.68\n",
    "- 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fa0ce-1cfa-421f-b3a2-13760f3255e9",
   "metadata": {},
   "source": [
    "Answer: 0.7254 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba1a3c-d292-40c6-9015-eff3f34f6d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
