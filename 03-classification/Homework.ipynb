{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21f3509f-c4f3-4933-886b-fd840684bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df944a54-c95b-409d-8017-16b0a22b289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdaafe3-de8c-4096-8bcd-dbb1e6f1d2d9",
   "metadata": {},
   "source": [
    "# Date preparation\n",
    "\n",
    "Check if the missing values are presented in the features.\n",
    "- If there are missing values:\n",
    "- For categorical features, replace them with 'NA'\n",
    "- For numerical features, replace with with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b688b2a-a599-4f42-98aa-d88fd82d54ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b505c9a3-a838-43a5-bfb0-9bfff44064f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_source', 'industry', 'annual_income', 'employment_status',\n",
       "       'location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df111261-9505-4dad-9fe6-89087efaf354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income',\n",
       "       'employment_status', 'location', 'interaction_count', 'lead_score',\n",
       "       'converted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900c71cb-6ddc-4ff7-9be6-8102b7cd9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].fillna('NA')\n",
    "        else:\n",
    "            df[col] = df[col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6242fae-42a5-4c2f-909a-a105b2a86d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads          NA                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3                NA      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d2c022-3b43-4490-affa-7ee0ad2f0c23",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column industry?\n",
    "\n",
    "- NA\n",
    "- technology\n",
    "- healthcare\n",
    "- retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dcba3ff-9996-46d1-a123-9ecac129bcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3db96-7e37-4005-bb47-cd4bacc28e46",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "number_of_courses_viewed, annual_income, interaction_count, lead_score\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- interaction_count and lead_score\n",
    "- number_of_courses_viewed and lead_score\n",
    "- number_of_courses_viewed and interaction_count\n",
    "- annual_income and interaction_count\n",
    "\n",
    "Only consider the pairs above when answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f064e5a4-ecc1-4492-9323-8ea5d6fd4da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n"
     ]
    }
   ],
   "source": [
    "cols = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "corr_matrix = df[cols].corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b83c8-06b8-44b1-b440-21b1d9ab1cbd",
   "metadata": {},
   "source": [
    "The answer is annual_income and interaction_count (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc79d263-c486-4593-896d-651a607e7b7a",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "- Make sure that the target value converted is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a9afd88-0cb1-44d7-a8f9-a2014dfa8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your target column is called 'target'\n",
    "X = df.drop(columns=['converted'])\n",
    "y = df['converted']\n",
    "\n",
    "# First split into train (60%) and temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Then split temp into val (20%) and test (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1047288-7427-490c-8beb-d2e5b2e16077",
   "metadata": {},
   "source": [
    "X_val['annual_income']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399931a-fd53-4ca5-8910-c20099ff5d99",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "- Calculate the mutual information score between converted and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using round(score, 2).\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- industry\n",
    "- location\n",
    "- lead_source\n",
    "- employment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2090082b-5265-422d-9125-2cbfd41da8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source: 0.03\n",
      "industry: 0.02\n",
      "employment_status: 0.02\n",
      "location: 0.0\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    score = mutual_info_score(X_train[col], y_train)\n",
    "    print(f\"{col}: {round(score, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010ef81-ba8e-46c9-8a58-c2cd610b8ed1",
   "metadata": {},
   "source": [
    "answer: lead_source (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918b292-eb26-406a-a734-29490212e187",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "0.64\n",
    "0.74\n",
    "0.84\n",
    "0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c23fbf-9f40-47b5-87af-d30a38479e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "#encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_cat = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_val_cat = encoder.transform(X_val[categorical_cols])\n",
    "\n",
    "# Drop categorical columns from original data and concatenate one-hot encoded columns\n",
    "X_train_num = X_train.drop(columns=categorical_cols).values\n",
    "X_val_num = X_val.drop(columns=categorical_cols).values\n",
    "\n",
    "X_train_final = np.hstack([X_train_num, X_train_cat])\n",
    "X_val_final = np.hstack([X_val_num, X_val_cat])\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_val_final)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(round(acc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c643ec-1baa-4ba3-a36a-deceec580051",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "- Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "'industry'\n",
    "'employment_status'\n",
    "'lead_score'\n",
    "Note: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77e440ca-eea1-4fb3-a41e-11e17278b7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source: 0.0137\n",
      "industry: 0.0\n",
      "number_of_courses_viewed: 0.0651\n",
      "annual_income: -0.113\n",
      "employment_status: -0.0034\n",
      "location: 0.0\n",
      "interaction_count: 0.0685\n",
      "lead_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# List of features to test\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_cat = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_val_cat = encoder.transform(X_val[categorical_cols])\n",
    "X_train_num = X_train.drop(columns=categorical_cols).values\n",
    "X_val_num = X_val.drop(columns=categorical_cols).values\n",
    "X_train_full = np.hstack([X_train_num, X_train_cat])\n",
    "X_val_full = np.hstack([X_val_num, X_val_cat])\n",
    "\n",
    "# Train model with all features\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_full, y_train)\n",
    "y_pred = model.predict(X_val_full)\n",
    "original_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Store accuracy differences\n",
    "acc_diffs = {}\n",
    "\n",
    "for feature in features:\n",
    "    # Exclude feature\n",
    "    X_train_drop = X_train.drop(columns=[feature])\n",
    "    X_val_drop = X_val.drop(columns=[feature])\n",
    "    # One-hot encode\n",
    "    cat_cols_drop = [col for col in X_train_drop.columns if X_train_drop[col].dtype == 'object']\n",
    "    encoder_drop = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    X_train_cat_drop = encoder_drop.fit_transform(X_train_drop[cat_cols_drop])\n",
    "    X_val_cat_drop = encoder_drop.transform(X_val_drop[cat_cols_drop])\n",
    "    X_train_num_drop = X_train_drop.drop(columns=cat_cols_drop).values\n",
    "    X_val_num_drop = X_val_drop.drop(columns=cat_cols_drop).values\n",
    "    X_train_final = np.hstack([X_train_num_drop, X_train_cat_drop])\n",
    "    X_val_final = np.hstack([X_val_num_drop, X_val_cat_drop])\n",
    "    # Train and evaluate\n",
    "    model_drop = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_drop.fit(X_train_final, y_train)\n",
    "    y_pred_drop = model_drop.predict(X_val_final)\n",
    "    acc_drop = accuracy_score(y_val, y_pred_drop)\n",
    "    acc_diffs[feature] = round(original_acc - acc_drop, 4)\n",
    "\n",
    "# Print accuracy differences\n",
    "for feature, diff in acc_diffs.items():\n",
    "    print(f\"{feature}: {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91934740-3c7b-4e70-8030-39194d932646",
   "metadata": {},
   "source": [
    "Multiple answers... Go with industry..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe22c9d-4a22-4529-a66a-3eb44f198eda",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "- Train models using all the features.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "0.01\n",
    "0.1\n",
    "1\n",
    "10\n",
    "100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc48cdb7-8000-4193-b941-167fe4aade58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: 0.74315\n",
      "C=0.1: 0.74315\n",
      "C=1: 0.74315\n",
      "C=10: 0.74315\n",
      "C=100: 0.74315\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_cat = encoder.fit_transform(X_train[categorical_cols])\n",
    "X_val_cat = encoder.transform(X_val[categorical_cols])\n",
    "X_train_num = X_train.drop(columns=categorical_cols).values\n",
    "X_val_num = X_val.drop(columns=categorical_cols).values\n",
    "X_train_final = np.hstack([X_train_num, X_train_cat])\n",
    "X_val_final = np.hstack([X_val_num, X_val_cat])\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_final, y_train)\n",
    "    y_pred = model.predict(X_val_final)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"C={C}: {round(acc, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f779d-eaf6-4f28-97f3-64499f11014d",
   "metadata": {},
   "source": [
    "answer: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f8879db-09a0-4d5a-946e-70a8069fb897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 6.1705e+04, 4.0000e+00, 6.5000e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 5.5199e+04, 4.0000e+00, 9.0000e-02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 4.0841e+04, 4.0000e+00, 6.1000e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [1.0000e+00, 2.8242e+04, 3.0000e+00, 8.4000e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [0.0000e+00, 6.4775e+04, 3.0000e+00, 7.0000e-01, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e70ca6-05b6-4900-bb55-8f65d5944df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
